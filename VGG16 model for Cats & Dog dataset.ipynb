{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f4b5174",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models\n",
    "import keras,os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "#import  keras.application s\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30cc3135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400 images belonging to 2 classes.\n",
      "Found 202 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "trdata=ImageDataGenerator()\n",
    "traindata=trdata.flow_from_directory(directory=r'C:/Users/salma/data/train',target_size=(224,224))\n",
    "tsdata=ImageDataGenerator()\n",
    "testdata=tsdata.flow_from_directory(directory=r'C:/Users/salma/data/test',target_size=(224,224))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "831ae654",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg=keras.applications.VGG16(input_shape=(224,224,3),include_top=False,weights=\"imagenet\")\n",
    "vgg.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "33173042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_273 (Conv2D)         (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " conv2d_274 (Conv2D)         (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " max_pooling2d_105 (MaxPooli  (None, 112, 112, 64)     0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_275 (Conv2D)         (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " conv2d_276 (Conv2D)         (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " max_pooling2d_106 (MaxPooli  (None, 56, 56, 128)      0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_277 (Conv2D)         (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " conv2d_278 (Conv2D)         (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " conv2d_279 (Conv2D)         (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " max_pooling2d_107 (MaxPooli  (None, 28, 28, 256)      0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_280 (Conv2D)         (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " conv2d_281 (Conv2D)         (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_282 (Conv2D)         (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " max_pooling2d_108 (MaxPooli  (None, 14, 14, 512)      0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_283 (Conv2D)         (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_284 (Conv2D)         (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_285 (Conv2D)         (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " max_pooling2d_109 (MaxPooli  (None, 7, 7, 512)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 256)               6422784   \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 2)                 514       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,203,778\n",
      "Trainable params: 6,489,090\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model.load_weights(r'C:/Users/salma/data/vggweights.h5')\n",
    "for layer in model.layers:\n",
    "    layer.trainable=False\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=256,activation=\"relu\"))\n",
    "model.add(Dense(units=256,activation=\"relu\"))\n",
    "model.add(Dense(units=2, activation=\"softmax\"))\n",
    "\n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9be2538e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = \"adam\", loss = keras.losses.categorical_crossentropy, metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a7365d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\salma\\AppData\\Local\\Temp/ipykernel_13316/484573152.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(steps_per_epoch=10,generator=traindata,validation_data=testdata,epochs = 2,validation_steps=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "10/10 [==============================] - ETA: 0s - loss: 26.3040 - accuracy: 0.6184WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10 batches). You may need to use the repeat() function when building your dataset.\n",
      "10/10 [==============================] - 108s 11s/step - loss: 26.3040 - accuracy: 0.6184 - val_loss: 1.7034 - val_accuracy: 0.8861\n",
      "Epoch 2/2\n",
      "10/10 [==============================] - 67s 7s/step - loss: 1.8674 - accuracy: 0.9094\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(steps_per_epoch=10,generator=traindata,validation_data=testdata,epochs = 2,validation_steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "45a34ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights1\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('weights1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "34a79f6b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/test_set/test_set/dogs/dog.4002.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13316/256412314.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mimg_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/test_set/test_set/dogs/dog.4002.jpg'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mimg_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\image_utils.py\u001b[0m in \u001b[0;36mload_img\u001b[1;34m(path, grayscale, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[0;32m    391\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m       \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 393\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    394\u001b[0m       \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/test_set/test_set/dogs/dog.4002.jpg'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import pandas as pd\n",
    "img_pred=image.load_img('/content/test_set/test_set/dogs/dog.4002.jpg',target_size=(150,150))\n",
    "\n",
    "img_pred=image.img_to_array(img_pred)\n",
    "img_pred=np.expand_dims(img_pred,axis=0)\n",
    "\n",
    "rslt=model.predict(img_pred)\n",
    "print(rslt)\n",
    "if rslt[0][0]==1:\n",
    "  prediction='Dog'\n",
    "else:\n",
    "  prediction='Cat'\n",
    "print('Prediction:',prediction)\n",
    "\n",
    "img=npimg.imread('/content/test_set/test_set/cats/cat.4004.jpg')\n",
    "imgplot=plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34b75f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
